{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from wildlife_datasets import datasets, loader\n",
    "from wildlife_tools.data import WildlifeDataset\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections.abc import Iterable\n",
    "\n",
    "class WD(WildlifeDataset):\n",
    "    def plot_grid(self, **kwargs):\n",
    "        self_copy = copy.deepcopy(self)\n",
    "        self_copy.transform = None\n",
    "        self_copy.load_label = False\n",
    "        loader = lambda k: self_copy.__getitem__(k)\n",
    "        rotate = kwargs.pop('rotate', False)\n",
    "        return datasets.DatasetFactory(self.root, self.metadata).plot_grid(rotate=rotate, loader=loader, **kwargs)\n",
    "\n",
    "    def plot_predictions(self, y_true, y_pred, **kwargs):\n",
    "        if not isinstance(y_true, Iterable) and np.array(y_pred).ndim == 1:\n",
    "            y_true = [y_true]\n",
    "            y_pred = [y_pred]\n",
    "        if len(y_true) > 1:\n",
    "            header_cols = [\"Query\", \"\"] + [f\"Match {i+1}\" for i in range(len(y_pred[0]))]\n",
    "        else:\n",
    "            identity = self.metadata['identity'].to_numpy()\n",
    "            header_cols = [identity[y_true[0]], \"\"] + [identity[y_p] for y_p in y_pred[0]]\n",
    "        n_cols = len(header_cols)\n",
    "        idx = []\n",
    "        for y_t, y_p in zip(y_true, y_pred):\n",
    "            idx.append([y_t, -1] + list(y_p))\n",
    "        n_rows = kwargs.pop('n_rows', min(len(y_true), 5))\n",
    "        return self.plot_grid(idx=idx, n_rows=n_rows, n_cols=n_cols, header_cols=header_cols, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildlife_tools.similarity import CosineSimilarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: come up with a normal name\n",
    "def compute_predictions_disjoint(features, k=4, batch_size=1000):\n",
    "    # TODO: add check that features is a square matrix\n",
    "    n_query = len(features)\n",
    "    n_chunks = int(np.ceil(n_query / batch_size))\n",
    "    chunks = np.array_split(range(n_query), n_chunks)\n",
    "\n",
    "    matcher = CosineSimilarity()\n",
    "    idx_pred = np.zeros((n_query, k), dtype=np.int32)\n",
    "    for chunk in chunks:\n",
    "        similarity = matcher(query=features[chunk], database=features)['cosine']\n",
    "        idx_x = np.arange(len(chunk))\n",
    "        idx_y = np.arange(chunk[0], chunk[0]+len(chunk))\n",
    "        similarity[idx_x, idx_y] = -1        \n",
    "        idx_pred[chunk,:] = (-similarity).argsort(axis=-1)[:, :k]\n",
    "    idx_true = np.array(range(n_query))    \n",
    "    return idx_true, idx_pred    \n",
    "\n",
    "def find_wrong_labels(dataset, idx_true, idx_pred, k=4):\n",
    "    idx_true_wrong = []\n",
    "    idx_pred_wrong = []\n",
    "    for i, js in zip(idx_true, idx_pred):\n",
    "        y_true = dataset.metadata['identity'].iloc[i]\n",
    "        y_pred = dataset.metadata['identity'].iloc[js]\n",
    "        pred_counts = pd.Series(y_pred).value_counts()\n",
    "        for j in range(len(pred_counts)):\n",
    "            if pred_counts.iloc[j] < 3:\n",
    "                break\n",
    "            if pred_counts.index[j] != y_true:\n",
    "                idx_true_wrong.append(i)\n",
    "                idx_pred_wrong.append(js[:min(k,len(js))])\n",
    "    return idx_true_wrong, idx_pred_wrong\n",
    "\n",
    "def verify_wrong_labels(load_image, keypoint_extractor, keypoint_matcher, image_matcher, dataset, idx_true, idx_pred):\n",
    "    for i, js in zip(idx_true, idx_pred):\n",
    "        img1 = load_image(i)\n",
    "        for j in js:\n",
    "            if dataset.metadata['identity'].iloc[i] != dataset.metadata['identity'].iloc[j]:\n",
    "                img2 = load_image(j)\n",
    "\n",
    "                kpt1, desc1 = keypoint_extractor.generate_keypoints(img1)\n",
    "                kpt2, desc2 = keypoint_extractor.generate_keypoints(img2)\n",
    "\n",
    "                matches = keypoint_matcher.compute_match(kpt1, desc1, kpt2, desc2)\n",
    "                matched = image_matcher.compute_matches_info(kpt1, kpt2, matches)[0]\n",
    "                if matched:\n",
    "                    fig = dataset.plot_predictions(i, js)\n",
    "                    plt.show(fig)\n",
    "                    plt.close(fig)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\"hf-hub:BVRA/wildlife-mega-L-384\", pretrained=True)\n",
    "transform = T.Compose([\n",
    "    T.Resize(size=(384, 384)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../Turtles_Identification/src')\n",
    "\n",
    "from image_loader import Loader\n",
    "from keypoint_extractor import SIFT\n",
    "from keypoint_matcher import L1Matcher\n",
    "from image_matcher import AlignMatcher\n",
    "\n",
    "keypoint_extractor = SIFT()\n",
    "keypoint_matcher = L1Matcher()\n",
    "image_matcher = AlignMatcher(n_keypoints=10, method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from collections.abc import Iterable\n",
    "\n",
    "for dataset_name in datasets.names_all:\n",
    "    print(dataset_name)\n",
    "    metadata = loader.load_dataset(dataset_name, '../data', '../data/_dataframes/')\n",
    "    if metadata.__class__.__name__ in ['Drosophila']:\n",
    "        print('Skipping dataset')\n",
    "        continue\n",
    "    print('Loading dataset')\n",
    "    if 'bbox' in metadata.df.columns:\n",
    "        for i_row, df_row in metadata.df.iterrows():\n",
    "            if not isinstance(df_row['bbox'], Iterable):\n",
    "                img = datasets.utils.get_image(os.path.join(metadata.root, df_row['path']))\n",
    "                metadata.df.at[i_row, 'bbox'] = [0, 0, img.size[0], img.size[1]]\n",
    "        dataset = WD(metadata.df, metadata.root, img_load=\"bbox\", transform=transform)    \n",
    "    else:\n",
    "        dataset = WD(metadata.df, metadata.root, img_load=\"crop_black\", transform=transform)\n",
    "    features = np.load('../data/_features/features_' + dataset_name.__name__ + '.npy')\n",
    "    \n",
    "    if 'bbox' in metadata.df.columns:\n",
    "        dataset_loader = WD(metadata.df, metadata.root, img_load=\"bbox\", transform=T.Resize(size=(256, 256))) \n",
    "    else:\n",
    "        dataset_loader = WD(metadata.df, metadata.root, img_load=\"crop_black\", transform=T.Resize(size=(256, 256)))\n",
    "    def load_image(k):\n",
    "        return np.array(dataset_loader[k][0])\n",
    "\n",
    "    print('Computing predictions')\n",
    "    idx_true, idx_pred = compute_predictions_disjoint(features)    \n",
    "    print('Finding potenially wrong labels')\n",
    "    idx_true, idx_pred = find_wrong_labels(dataset, idx_true, idx_pred)\n",
    "    print('Found potential %d wrong labels' % len(idx_true))\n",
    "    #dataset.plot_predictions(idx_true, idx_pred)\n",
    "    print('Verifying predictions')\n",
    "    verify_wrong_labels(load_image, keypoint_extractor, keypoint_matcher, image_matcher, dataset, idx_true, idx_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_wt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
