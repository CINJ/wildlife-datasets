{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster\n",
    "from wildlife_datasets import datasets, loader, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dataset = '../data/'\n",
    "root_dataframe = '../data/_dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(x, y, digits=1):\n",
    "    if y == 0:\n",
    "        return 'inf'\n",
    "    else:\n",
    "        r = np.round(100*x/y, digits)\n",
    "        return str(r) + '%'\n",
    "\n",
    "def get_metrics(results, identity, clusters, prefix=''):\n",
    "    df = pd.DataFrame({'identity': identity, 'clusters': clusters})\n",
    "    \n",
    "    n_correct_cluster = 0\n",
    "    n_wrong_cluster = 0\n",
    "    identity_in_clusters = []    \n",
    "    for cluster, df_cluster in df.groupby('clusters'):\n",
    "        if cluster >= 0:\n",
    "            identity_counts = df_cluster['identity'].value_counts().sort_values(ascending=False)            \n",
    "            n_correct_cluster += identity_counts.iloc[0]\n",
    "            n_wrong_cluster += np.sum(identity_counts.iloc[1:])\n",
    "            identity_in_clusters.append(identity_counts.index[0])\n",
    "\n",
    "    n_no_cluster = np.sum(df['clusters'] == -1)\n",
    "    n_identities = df['identity'].nunique()\n",
    "    n_identities_in_clusters = pd.Series(identity_in_clusters).nunique()\n",
    "    results[prefix + 'missed_identities'] = ratio(n_identities-n_identities_in_clusters, n_identities)\n",
    "    results[prefix + 'multiple_identities'] = ratio(len(identity_in_clusters), n_identities_in_clusters)\n",
    "    results[prefix + 'no_cluster'] = ratio(n_no_cluster, len(df))\n",
    "    results[prefix + 'correct_cluster'] = ratio(n_correct_cluster, len(df))\n",
    "    results[prefix + 'wrong_cluster'] = ratio(n_wrong_cluster, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of the similarity matrix must be batched\n",
    "\n",
    "k = 10\n",
    "names = []\n",
    "results_all = []\n",
    "for d_name in datasets.names_all:\n",
    "    print(d_name)\n",
    "    file_name = f'../data/_features/features_{d_name.__name__}.npy'\n",
    "    d = loader.load_dataset(d_name, root_dataset, root_dataframe)\n",
    "    if os.path.exists(file_name) and len(d.df) <= 10000:\n",
    "        names.append(d_name.__name__)\n",
    "        results = {}\n",
    "\n",
    "        output = np.load(file_name)\n",
    "        for i in range(len(output)):\n",
    "            output[i] /= np.linalg.norm(output[i])\n",
    "        \n",
    "        similarity = output @ output.T\n",
    "        np.fill_diagonal(similarity, -1)        \n",
    "        idx = (-similarity).argsort(axis=-1)[:, :k]\n",
    "        pred = [d.df['identity'].iloc[idx[i]].values for i in range(len(d.df))]\n",
    "        map = metrics.mean_average_precision(d.df['identity'].values, pred)\n",
    "        results['map'] = ratio(map, 1)\n",
    "        \n",
    "        db = cluster.DBSCAN().fit(output)\n",
    "        get_metrics(results, d.df['identity'].to_numpy(), db.labels_, prefix='l2_')\n",
    "        \n",
    "        db = cluster.DBSCAN(metric='cosine').fit(output)\n",
    "        get_metrics(results, d.df['identity'].to_numpy(), db.labels_, prefix='cos_')\n",
    "\n",
    "        results_all.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = pd.DataFrame(results_all)\n",
    "results_all.index = names\n",
    "results_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
