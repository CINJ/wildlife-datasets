```python exec="true" name="run"
from wildlife_datasets import datasets, analysis, loader
import pandas as pd

df = pd.read_csv('docs/csv/MacaqueFaces.csv')
df = df.drop('Unnamed: 0', axis=1)
dataset = datasets.MacaqueFaces('', df)
```

# How to use datasets

The central part of the library is the `DatasetFactory` class, more specifically its subclasses. They represent wildlife datasets and manage any operations on them. `DatasetFactory` handles downloads, conversions to dataframes, and splitting to training and testing set. Additionally, `DatasetFactory` can create dataset summary and provides access to its metadata.

The commands listed at this page require the following imports:

```python
from wildlife_datasets import datasets, analysis, loader
```

## Downloading datasets

Most of the datasets used in this library can be downloaded fully automatically either via a script or via a `dataset` module. However, some of them are require special handling as described in a [special page](../downloads). 

### Using script
You can use Python scripts that are located in the `download` module.
Each script can be used as follows:

    python3 macaque_faces.py

You can also manually specify the location and name of the dataset folder by the optional flags:

    python3 macaque_faces.py --name 'MacaqueFaces' --output 'data'

### Using dataset module
The Python script can be also called from the `DatasetFactory` class

```python
datasets.MacaqueFaces.download.get_data('data/MacaqueFaces')
```

## Listing datasets
All exported datasets can be listed by

```python exec="true" source="above" result="console" name="run"
datasets.dataset_names
print(['wildlife_datasets.datasets.datasets.' + d.__name__ for d in datasets.dataset_names]) # markdown-exec: hide
```

All these classes are subclasses of the parent class `DatasetFactory`.


## Working with one dataset
When a dataset is already downloaded, it can be loaded by

<!---
The following block is not run because it is loaded
at the beginning of the file.
Running this block would result in an error as 
the data is not downloaded.
-->

```python
dataset = datasets.MacaqueFaces('data/MacaqueFaces')
```

Since this a subclass of the `DatasetFactory` parent class, it inherits all the methods and attributes listed in its [documentation](reference_datasets.md). Its main component is the [pandas dataframe](../dataframe) of all samples

```python exec="true" source="above" result="console" name="run"
dataset.df
print(dataset.df) # markdown-exec: hide
```

and its reduced version possibly more suitable for machine learning tasks
    
```python exec="true" source="above" result="console" name="run"
dataset.df_ml
print(dataset.df_ml) # markdown-exec: hide
```

This second dataframe removed all individual which were not known or which had only one photo.

The dataset can be graphically visualized by the grid plot

```python
analysis.plot_grid(dataset.df, 'data/MacaqueFaces')
```

![](images/grid_MacaqueFaces.png)

or its basic numerical statistics can by printed by

<!---
The following block is not run because it prints
to the console and not to the output block.
-->

```python
analysis.display_statistics(dataset.df)
```

    Number of identitites            34
    Number of all animals            6280
    Number of animals with one image 0
    Number of unidentified animals   0
    Number of animals in dataframe   6280
    Images span                      1.4 years

or [metadata](../dataframe#metadata) displayed by

```python exec="true" source="above" result="console" name="run"
dataset.metadata
print(dataset.metadata) # markdown-exec: hide
```

## Working with multiple datasets
Since the above-mentioned way of creating the datasets always recreates the dataframe, it will be slow for larger datasets. For this reason, we provide an alternative way

```python
loader.load_dataset(datasets.MacaqueFaces, 'data', 'dataframes')
```

This function first checks whether `dataframes/MacaqueFaces.pkl` exists. If so, it will load the dataframe stored there, otherwise, it will create this file. Therefore, the first call of this function may be slow but the following calls are fast.


!!! warning

    The following code needs to have all datasets downloaded. If you have downloaded only some of them, select the appropriate subset of `datasets.dataset_names`.

To work with all provided datasets, we can easily put this function call into a loop

```python
ds = []
for dataset in datasets.dataset_names:
    d = loader.load_dataset(dataset, 'data', 'dataframes')
    ds.append(d)
```

or equivalently by

```python
loader.load_datasets(datasets.dataset_names, 'data', 'dataframes')
```
