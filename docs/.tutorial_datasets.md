```python exec="true" name="run"
import contextlib, io

def run(str):
    f = io.StringIO()
    with contextlib.redirect_stdout(f):
        eval(str)
    output = f.getvalue()
    return output
```

```python exec="true" name="run"
from wildlife_datasets import analysis, datasets, loader
import pandas as pd

df = pd.read_csv('docs/csv/MacaqueFaces.csv')
df = df.drop('Unnamed: 0', axis=1)
d = datasets.MacaqueFaces('', df)
```


# How to work with datasets

The library represents wildlife re-identification datasets and manages any operations on them such as downloads, conversions to dataframes, splitting to training and testing sets, and printing dataset summary or its metadata. We import first the required modules

```python
from wildlife_datasets import analysis, datasets, loader
```

## Downloading datasets

Most of the datasets used in this library can be downloaded fully automatically either via the `datasets` module. However, some of them are require special handling as described in a [special page](../downloads). 

```python
datasets.MacaqueFaces.get_data('data')
```

## Listing datasets

All exported datasets can be listed by

```python exec="true" source="above" result="console" name="run"
datasets.dataset_names
print(['wildlife_datasets.datasets.datasets.' + dataset_name.__name__ for dataset_name in datasets.dataset_names]) # markdown-exec: hide
```

All these classes are subclasses of its parent class `DatasetFactory`.


## Working with one dataset
When a dataset is already downloaded, it can be loaded by

<!---
The following block is not run because it is loaded
at the beginning of the file.
Running this block would result in an error as 
the data is not downloaded.
-->

```python
d = datasets.MacaqueFaces('data/MacaqueFaces')
```

Since this a subclass of the `DatasetFactory` parent class, it inherits all the methods and attributes listed in its [documentation](reference_datasets.md). Its main component is the [pandas dataframe](../dataframe) of all samples

```python exec="true" source="above" result="console" name="run"
d.df
print(d.df) # markdown-exec: hide
```

and its reduced version possibly more suitable for machine learning tasks
    
```python exec="true" source="above" result="console" name="run"
d.df_ml
print(d.df_ml) # markdown-exec: hide
```

This second dataframe removed all individuals which were not known or which had only one photo (sample).

The dataset can be graphically visualized by the grid plot

```python
analysis.plot_grid(d.df, 'data/MacaqueFaces')
```

![](images/grid_MacaqueFaces.png)

or its basic numerical statistics can by printed by

```python exec="true" source="above" result="console" name="run"
analysis.display_statistics(d.df)

print(run('analysis.display_statistics(d.df)')) # markdown-exec: hide
```

or [metadata](../dataframe#metadata) displayed by

```python exec="true" source="above" result="console" name="run"
d.metadata
print(d.metadata) # markdown-exec: hide
```

## Working with multiple datasets
Since the above-mentioned way of creating the datasets always recreates the dataframe, it will be slow for larger datasets. For this reason, we provide an alternative way

```python
d = loader.load_dataset(datasets.MacaqueFaces, 'data', 'dataframes')
```

This function first checks whether `dataframes/MacaqueFaces.pkl` exists. If so, it will load the dataframe stored there, otherwise, it will create this file. Therefore, the first call of this function may be slow but the following calls are fast.


!!! warning

    The following code needs to have all datasets downloaded. If you have downloaded only some of them, select the appropriate subset of `datasets.dataset_names`.

To work with all provided datasets, we can easily put this function call into a loop

```python
ds = []
for dataset_name in datasets.dataset_names:
    d = loader.load_dataset(dataset_name, 'data', 'dataframes')
    ds.append(d)
```

or equivalently by

```python
ds = loader.load_datasets(datasets.dataset_names, 'data', 'dataframes')
```
